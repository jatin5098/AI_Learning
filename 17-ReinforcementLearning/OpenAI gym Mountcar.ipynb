{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228ca0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from gym) (0.0.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pygame in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (2.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install pygame\n",
    "# !pip install --upgrade gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfd8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cf9f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gym.envs.registration.registry.all()\n",
    "from gym import envs\n",
    "envs.registry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffc44ee1-5b7b-4768-8ba1-5eaf9a81b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(gym.envs.registration.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712202cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"MountainCar-v0\"\n",
    "env = gym.make(env_name,  render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfda017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154b0a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position:-0.5961402058601379, Velocity: 0.0005437578656710684, reward:-1.0\n",
      "Position:-0.5960566997528076, Velocity: 8.353446901310235e-05, reward:-1.0\n",
      "Position:-0.5944340229034424, Velocity: 0.001622699317522347, reward:-1.0\n",
      "Position:-0.593284010887146, Velocity: 0.0011499739484861493, reward:-1.0\n",
      "Position:-0.5916152000427246, Velocity: 0.001668814686127007, reward:-1.0\n",
      "Position:-0.5894398093223572, Velocity: 0.002175405388697982, reward:-1.0\n",
      "Position:-0.5877737998962402, Velocity: 0.001666008378379047, reward:-1.0\n",
      "Position:-0.5856294631958008, Velocity: 0.0021443532314151525, reward:-1.0\n",
      "Position:-0.5820225477218628, Velocity: 0.0036069026682525873, reward:-1.0\n",
      "Position:-0.5789796710014343, Velocity: 0.003042840864509344, reward:-1.0\n",
      "Position:-0.5765234231948853, Velocity: 0.0024562894832342863, reward:-1.0\n",
      "Position:-0.5746718645095825, Velocity: 0.0018515586853027344, reward:-1.0\n",
      "Position:-0.571438729763031, Velocity: 0.0032331098336726427, reward:-1.0\n",
      "Position:-0.5678480863571167, Velocity: 0.0035906790290027857, reward:-1.0\n",
      "Position:-0.5629264712333679, Velocity: 0.0049215746112167835, reward:-1.0\n",
      "Position:-0.5567106604576111, Velocity: 0.006215848959982395, reward:-1.0\n",
      "Position:-0.5512468814849854, Velocity: 0.00546377943828702, reward:-1.0\n",
      "Position:-0.5465759634971619, Velocity: 0.004670902621001005, reward:-1.0\n",
      "Position:-0.5407328605651855, Velocity: 0.005843095015734434, reward:-1.0\n",
      "Position:-0.5337613224983215, Velocity: 0.006971544120460749, reward:-1.0\n",
      "Position:-0.5267135500907898, Velocity: 0.007047751452773809, reward:-1.0\n",
      "Position:-0.5186424255371094, Velocity: 0.008071111515164375, reward:-1.0\n",
      "Position:-0.5116085410118103, Velocity: 0.0070339408703148365, reward:-1.0\n",
      "Position:-0.503664493560791, Velocity: 0.007944033481180668, reward:-1.0\n",
      "Position:-0.49586987495422363, Velocity: 0.007794615346938372, reward:-1.0\n",
      "Position:-0.4882829785346985, Velocity: 0.007586888037621975, reward:-1.0\n",
      "Position:-0.4809604585170746, Velocity: 0.007322514895349741, reward:-1.0\n",
      "Position:-0.4739568531513214, Velocity: 0.0070035988464951515, reward:-1.0\n",
      "Position:-0.46632421016693115, Velocity: 0.0076326592825353146, reward:-1.0\n",
      "Position:-0.4581190049648285, Velocity: 0.008205210790038109, reward:-1.0\n",
      "Position:-0.4514017403125763, Velocity: 0.006717264652252197, reward:-1.0\n",
      "Position:-0.4452217221260071, Velocity: 0.00618001027032733, reward:-1.0\n",
      "Position:-0.43862414360046387, Velocity: 0.006597584113478661, reward:-1.0\n",
      "Position:-0.4336569905281067, Velocity: 0.00496715446934104, reward:-1.0\n",
      "Position:-0.42835623025894165, Velocity: 0.005300746764987707, reward:-1.0\n",
      "Position:-0.42276012897491455, Velocity: 0.005596107337623835, reward:-1.0\n",
      "Position:-0.4169088304042816, Velocity: 0.005851300433278084, reward:-1.0\n",
      "Position:-0.4108441174030304, Velocity: 0.006064718123525381, reward:-1.0\n",
      "Position:-0.40660902857780457, Velocity: 0.004235093481838703, reward:-1.0\n",
      "Position:-0.40323343873023987, Velocity: 0.0033755728509277105, reward:-1.0\n",
      "Position:-0.4007411301136017, Velocity: 0.0024923235177993774, reward:-1.0\n",
      "Position:-0.39914950728416443, Velocity: 0.001591612002812326, reward:-1.0\n",
      "Position:-0.3984697163105011, Velocity: 0.0006797753158025444, reward:-1.0\n",
      "Position:-0.39970654249191284, Velocity: -0.0012368065072223544, reward:-1.0\n",
      "Position:-0.4018512964248657, Velocity: -0.002144751837477088, reward:-1.0\n",
      "Position:-0.40588897466659546, Velocity: -0.004037691280245781, reward:-1.0\n",
      "Position:-0.41179126501083374, Velocity: -0.005902281031012535, reward:-1.0\n",
      "Position:-0.41851645708084106, Velocity: -0.00672520138323307, reward:-1.0\n",
      "Position:-0.4250167906284332, Velocity: -0.006500329356640577, reward:-1.0\n",
      "Position:-0.43124574422836304, Velocity: -0.006228963378816843, reward:-1.0\n",
      "Position:-0.4371585249900818, Velocity: -0.0059127830900251865, reward:-1.0\n",
      "Position:-0.4427123963832855, Velocity: -0.005553843453526497, reward:-1.0\n",
      "Position:-0.44886693358421326, Velocity: -0.006154555361717939, reward:-1.0\n",
      "Position:-0.4545772969722748, Velocity: -0.0057103605940938, reward:-1.0\n",
      "Position:-0.4618016183376312, Velocity: -0.007224330212920904, reward:-1.0\n",
      "Position:-0.4694867730140686, Velocity: -0.007685158401727676, reward:-1.0\n",
      "Position:-0.4765760004520416, Velocity: -0.007089218124747276, reward:-1.0\n",
      "Position:-0.48501673340797424, Velocity: -0.008440720848739147, reward:-1.0\n",
      "Position:-0.49274617433547974, Velocity: -0.0077294399961829185, reward:-1.0\n",
      "Position:-0.500706672668457, Velocity: -0.007960504852235317, reward:-1.0\n",
      "Position:-0.5078387260437012, Velocity: -0.00713206036016345, reward:-1.0\n",
      "Position:-0.5140889286994934, Velocity: -0.0062502166256308556, reward:-1.0\n",
      "Position:-0.5214104652404785, Velocity: -0.00732153095304966, reward:-1.0\n",
      "Position:-0.5287483930587769, Velocity: -0.007337942719459534, reward:-1.0\n",
      "Position:-0.5370477437973022, Velocity: -0.008299321867525578, reward:-1.0\n",
      "Position:-0.5442461967468262, Velocity: -0.007198482286185026, reward:-1.0\n",
      "Position:-0.5502899289131165, Velocity: -0.006043725181370974, reward:-1.0\n",
      "Position:-0.5561336874961853, Velocity: -0.0058437553234398365, reward:-1.0\n",
      "Position:-0.5617338418960571, Velocity: -0.0056001306511461735, reward:-1.0\n",
      "Position:-0.5680485963821411, Velocity: -0.0063147409819066525, reward:-1.0\n",
      "Position:-0.5740309357643127, Velocity: -0.005982354748994112, reward:-1.0\n",
      "Position:-0.5796365141868591, Velocity: -0.005605555139482021, reward:-1.0\n",
      "Position:-0.5838237404823303, Velocity: -0.0041872491128742695, reward:-1.0\n",
      "Position:-0.5885617733001709, Velocity: -0.0047380151227116585, reward:-1.0\n",
      "Position:-0.592815637588501, Velocity: -0.004253871273249388, reward:-1.0\n",
      "Position:-0.5955541133880615, Velocity: -0.002738467650488019, reward:-1.0\n",
      "Position:-0.5967570543289185, Velocity: -0.0012029842473566532, reward:-1.0\n",
      "Position:-0.5964157581329346, Velocity: 0.0003413085942156613, reward:-1.0\n",
      "Position:-0.5965326428413391, Velocity: -0.00011689724487951025, reward:-1.0\n",
      "Position:-0.5951068997383118, Velocity: 0.0014257527654990554, reward:-1.0\n",
      "Position:-0.593148946762085, Velocity: 0.0019579597283154726, reward:-1.0\n",
      "Position:-0.5916731357574463, Velocity: 0.0014758093748241663, reward:-1.0\n",
      "Position:-0.5896903276443481, Velocity: 0.0019828255753964186, reward:-1.0\n",
      "Position:-0.5882150530815125, Velocity: 0.001475270721130073, reward:-1.0\n",
      "Position:-0.5852581858634949, Velocity: 0.002956863259896636, reward:-1.0\n",
      "Position:-0.5828415155410767, Velocity: 0.0024166761431843042, reward:-1.0\n",
      "Position:-0.5789828300476074, Velocity: 0.0038586610462516546, reward:-1.0\n",
      "Position:-0.5737107396125793, Velocity: 0.0052721332758665085, reward:-1.0\n",
      "Position:-0.5670641660690308, Velocity: 0.00664655864238739, reward:-1.0\n",
      "Position:-0.5590925216674805, Velocity: 0.0079716257750988, reward:-1.0\n",
      "Position:-0.551855206489563, Velocity: 0.007237326353788376, reward:-1.0\n",
      "Position:-0.5454062223434448, Velocity: 0.006448995787650347, reward:-1.0\n",
      "Position:-0.537793755531311, Velocity: 0.007612434681504965, reward:-1.0\n",
      "Position:-0.5300748944282532, Velocity: 0.00771886482834816, reward:-1.0\n",
      "Position:-0.5233075022697449, Velocity: 0.006767433136701584, reward:-1.0\n",
      "Position:-0.5175422430038452, Velocity: 0.005765248090028763, reward:-1.0\n",
      "Position:-0.5108224153518677, Velocity: 0.0067198267206549644, reward:-1.0\n",
      "Position:-0.5051983594894409, Velocity: 0.005624026991426945, reward:-1.0\n",
      "Position:-0.4997122883796692, Velocity: 0.005486094392836094, reward:-1.0\n",
      "Position:-0.4954051673412323, Velocity: 0.004307098686695099, reward:-1.0\n"
     ]
    }
   ],
   "source": [
    "#env.seed(42)  # to make sure that we all have the same initial state\n",
    "observation = env.reset()  # reset all internal values\n",
    "\n",
    "for _ in range(100):\n",
    "  ###  0   | Accelerate to the left\n",
    "  ###  1   | Don't accelerate\n",
    "  ###  2   | Accelerate to the right\n",
    "\n",
    "    env.render()  # display the current state\n",
    "    action = env.action_space.sample()  # lets only accelerate forward\n",
    "    observation, reward, done, info, _ = env.step(action) # perform the random action on the current state of the environment\n",
    "    print(f\"Position:{observation[0]}, Velocity: {observation[1]}, reward:{reward}\")  # Take a look at the observations\n",
    "    time.sleep(0.1) ### when the statement time.sleep(t) is executed then the next line of code will be executed after t seconds.\n",
    "\n",
    "env.close()  # dont forget to close the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee9259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00054a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ((position > -0.1) & (position < 0.1)).any():  # if you current position falls in this intervall chose action 2 (drive forward)\n",
    "#         action = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95c3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chose_action(observation):\n",
    "    position, velocity = observation\n",
    "\n",
    "    if ((position > -0.1) & (position < 0.1)).any():  # if you current position falls in this intervall chose action 2 (drive forward)\n",
    "        action = 2\n",
    "\n",
    "    elif ((velocity < 0) & (position < -0.2)).any():  # if your velocity is negative and your position is smaller than -0.2 chose action 0 (drive backwards)\n",
    "        action = 0\n",
    "        \n",
    "    else:  # else do nothing\n",
    "        action = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17c6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.seed(42)\n",
    "\n",
    "env_name = \"MountainCar-v0\"\n",
    "env = gym.make(env_name,  render_mode='human')\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(500):\n",
    "    env.render()\n",
    "    action = chose_action(observation)\n",
    "    observation, reward, done, info,_ = env.step(action) \n",
    "    # time.sleep(0.01)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf538112",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The goal is to make the car stay at the flag position."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
